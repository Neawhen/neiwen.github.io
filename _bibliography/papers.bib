---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation,},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics,},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers,}
}


@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.,},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf}
}

@article{ling2022blastnet,
  abbr={SenSys'22},
  selected={true},
  title={BlastNet: Exploiting Duo-Blocks for Cross-Processor Real-Time DNN Inference},
  author={Ling, Neiwen and Huang, Xuan and Zhao, Zhihe and Guan, Nan and Yan, Zhenyu and Xing, Guoliang},
  journal={Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2022)},
  year={2022},
  award={Best Paper Finalist},
  accept={(Acceptance ratio: 52/208=25%)},
  abstract = {In recent years, Deep Neural Network (DNN) has been increasingly adopted by a wide range of time-critical applications running on 
  edge platforms with heterogeneous multiprocessors. To meet the stringent timing requirements of these applications, heterogeneous 
  CPU and GPU resources must be efficiently utilized for the inference of multiple DNN models. Such a cross-processor real-time 
  DNN inference paradigm poses major challenges due to the inherent performance imbalance among different processors and the lack 
  of real-time support for cross-processor inference from existing deep learning frameworks. In this work, we propose a new system 
  named BlastNet that exploits duo-block - a new model inference abstraction to support highly efficient cross-processor real-time DNN 
  inference. Each duo-block has a dual model structure, enabling efficient fine-grained inference alternatively across different processors. BlastNet employs a novel block-level Neural Architecture 
  Search (NAS) technique to generate duo-blocks, which accounts for computing characteristics and communication overhead. The duoblocks are optimized at design time and then dynamically scheduled 
  to achieve high resource utilization of heterogeneous CPU and GPU at runtime. BlastNet is implemented on an indoor autonomous driving platform and three popular edge platforms. Extensive results 
  show that BlastNet achieves 35.07 % less deadline missing rate with a mere 1.63% of model accuracy loss.},
  pdf = {blastnet_sensys2022.pdf},
  html={https://dl.acm.org/doi/abs/10.1145/3560905.3568520},
  slides={Blastnet-slides.pdf}
}

@article{ling2021rt,
  abbr={SenSys'21},
  selected={true},
  title={RT-mDL: Supporting Real-Time Mixed Deep Learning Tasks on Edge Platforms},
  author={Ling, Neiwen and Wang, Kai and He, Yuze and Xing, Guoliang and Xie, Daqi},
  abstract={Recent years have witnessed an emerging class of real-time applications, e.g., autonomous driving, in which resource-constrained edge platforms need to execute a set of real-time mixed Deep Learning (DL) tasks concurrently. Such an application paradigm poses major challenges due to the huge compute workload of deep neural network models, diverse performance requirements of different tasks, and the lack of real-time support from existing DL frameworks. In this paper, we present RT-mDL, a novel framework to support mixed real-time DL tasks on edge platform with heterogeneous CPU and GPU resource. 
  RT-mDL aims to optimize the mixed DL task execution to meet their diverse real-time/accuracy requirements by exploiting unique compute characteristics of DL tasks. RT-mDL employs a novel storage-bounded model scaling method to generate a series of model variants, and systematically optimizes the DL task execution by joint model variants selection and task priority assignment. To improve the CPU/GPU utilization of mixed DL tasks, RT-mDL also includes a new priority-based scheduler which employs a GPU packing mechanism and executes the CPU/GPU tasks independently.
  Our implementation on an F1/10 autonomous driving testbed shows that, RT-mDL can enable multiple concurrent DL tasks to achieve satisfactory real-time performance in traffic light detection and sign recognition. Moreover, compared to state-of-the-art baselines, RT-mDL can reduce deadline missing rate by 40.12\% while only sacrificing 1.7\% model accuracy. 
  },
  journal={Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2021)},
  pages={1--14},
  year={2021},
  doi={10.1145/3485730.3485938},
  html={https://dl.acm.org/doi/10.1145/3485730.3485938},
  pdf={RT-mDL_SenSys2021.pdf},
  accept={(Acceptance ratio: 25/139=17.98%)},
  video={https://www.youtube.com/watch?v=9Hh1NOyXqPU&t=8s},
  demo={https://www.youtube.com/watch?v=7-_t1MrIo04},
  slides={RT-mDL-slides.pdf}
}

@article{2024soar,
  abbr={MobiCom'24},
  selected={true},
  title={Soar: Design and Deployment of A Smart Roadside Infrastructure System for Autonomous Driving},
  author={Shi(co-primary), Shuyao and Ling(co-primary), Neiwen and Jiang(co-primary), Zhehao and Huang(co-primary), Xuan and He, Yuze and Zhao, Xiaoguang and Yang, Bufang and Bian, Chen and Xia, Jingfei and Yan, Zhenyu and Yeung, Raymond and Xing, Guoliang},
  journal = {The 30th Annual International Conference on Mobile Computing And Networking (ACM MobiCom 2024)},
  abstract={Recently, smart roadside infrastructure (SRI) has demonstrated the potential of achieving fully autonomous driving systems. 
  To explore the potential of infrastructure-assisted autonomous driving, this paper presents the design and deployment of Soar, 
  the first end-to-end SRI system specifically designed to support autonomous driving systems. 
  Soar consists of both software and hardware components carefully designed to overcome various system and physical challenges. Soar can leverage the existing operational infrastructure like street lampposts for a lower barrier of adoption. Soar adopts a new communication architecture that comprises a bi-directional multi-hop I2I network and a downlink I2V broadcast service, which are designed based on off-the-shelf 802.11ac interfaces in an integrated manner. 
  Soar also features a hierarchical DL task management framework to achieve desirable load balancing among nodes and enable them to collaborate efficiently to run multiple data-intensive autonomous driving applications. We deployed a total of 18 Soar nodes on existing lampposts on campus, which have been operational for over two years. Our real-world evaluation shows that Soar can support a diverse set of autonomous driving applications and achieve desirable real-time performance and high communication reliability. 
  Our findings and experiences in this work offer key insights into the development and deployment of next-generation smart roadside infrastructure and autonomous driving systems.},
  year={2024},
  pdf={soar_mobicom24.pdf},
  accept={(Acceptance ratio: 48/207=23.18%)},
  html={https://dl.acm.org/doi/10.1145/3636534.3649352},
}

@article{2024typefly,
  abbr={arxiv},
  title={TypeFly: Flying Drones with Large Language Model},
  author={Chen, Guojun and Yu, Xiaojing and Ling, Neiwen and Zhong, Lin},
  abstract={Recent advancements in robot control using large language models (LLMs) have demonstrated significant potential, primarily due to LLMs’ capabilities to understand natural language commands and generate executable plans in various
  languages. However, in real-time and interactive applications involving mobile robots, particularly drones, the sequential token generation process inherent to LLMs introduces substantial latency, i.e. response time, in control plan generation.
  In this paper, we present a system called TypeFly that tackles this problem using a combination of a novel programming language called MiniSpec and its runtime to reduce the plan generation time and drone response time. That is, instead of asking an LLM to write a program (robotic plan) in the popular but verbose Python, TypeFly gets it to do it in MiniSpec specially designed for token efficiency and stream interpretation. 
  Using a set of challenging drone tasks, we show that design choices made by TypeFly can reduce up to 62% response time and provide a more consistent user experience, enabling responsive and intelligent LLM-based drone control with efficient completion.},
  year={2024},
  pdf={typefly.pdf},
  journal={arXiv preprint arXiv:2312.14950},
  html={https://arxiv.org/abs/2312.14950},
}

@article{jiang2023coedge,
  abbr={IPSN'23},
  selected={true},
  title={CoEdge: A Cooperative Edge System for Distributed Real-Time Deep Learning Tasks},
  author={Jiang(co-primary), Zhehao and Ling(co-primary), Neiwen and Huang, Xuan and Shi, Shuyao and Wu, Chenhao and Zhao, Xiaoguang and Yan, Zhenyu and Xing, Guoliang},
  abstract={Recent years have witnessed the emergence of a new class of cooperative edge systems in which a large number of edge nodes can collaborate through local peer-to-peer connectivity. In this paper, we propose CoEdge, a novel cooperative edge system that can support concurrent data/compute-intensive deep learning (DL) models for distributed real-time applications such as city-scale traffic monitoring and autonomous driving. First, CoEdge includes a hierarchical DL task scheduling framework that dispatches DL tasks to edge
  nodes based on their computational profiles, communication overhead, and real-time requirements. Second, CoEdge can dramatically increase the execution efficiency of DL models by batching sensor data and aggregating the inferences of the same model. Finally, we propose a new edge containerization approach that enables an edge node to execute concurrent DL tasks by partitioning the CPU and GPU workloads into different containers. We extensively evaluate CoEdge on a self-deployed smart lamppost testbed on a university campus. 
  Our results show that CoEdge can achieve up to 82.32% reduction on deadline missing rate compared to baselines.},
  journal = {The 22nd ACM/IEEE Conference on Information Processing in Sensor Networks (ACM/IEEE IPSN 2023)},
  year={2023},
  pdf={coedge_ipsn23.pdf},
  accept={(Acceptance ratio: 22/83=26.51%)},
  html={https://dl.acm.org/doi/10.1145/3583120.3586955},
  slides={CoEdge_slides.pdf}
}


@article{zhao2022iot,
  abbr={SenSys'22Poster},
  selected={true},
  title={Aaron: Compile-time Kernel Adaptation for Multi-DNN Inference Acceleration on Edge GPU},
  author={Zhao, Zhihe and Ling, Neiwen and Guan, Nan and Xing, Guoliang},
  journal={Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
  year={2022},
  award={Best Poster Award},
  abstract={AI applications powered by deep learning are increasingly running on edge devices. Meanwhile, many real-world IoT applications demand multiple real-time tasks to run on the same device, for
  example, to achieve both object tracking and image segmentation simultaneously on an augmented reality glass. However, the current solutions can not yet support such multi-tenant real-time DNN inference 
  on edge devices. Techniques such as on-device model compression trade inference accuracy for speed, while traditional DNN compilers mainly focus on single-tenant DNN model optimization. 
  To fill this gap, we propose Aaron, which leverages DNN compiling techniques to accelerate multi-DNN inference on edge GPU based on compile-time kernel adaptation with no accuracy loss. 
  Aaron integrates both DNN graph and kernel optimization to maximize on-device parallelism and minimize contention brought by concurrent inference.},
  pdf={aaron_sensys2022.pdf},
  html={https://dl.acm.org/doi/10.1145/3560905.3568050}
}

@article{zhao2023unify,
  abbr={SenSys'23 Poster},
  title={Unifying On-device Tensor Program Optimization through Large Foundation Model},
  author={Zhao, Zhihe and Ling, Neiwen and Liu, Kaiwei and Guan, Nan and Xing, Guoliang},
  journal = {Proceedings of the 21th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2023)},
  pdf={sensys23-unifying.pdf},
  abstract={We present TensorBind, a novel approach aimed at unifying different hardware architectures for compilation optimization. 
  Our proposed framework establishes an embedding space to seamlessly bind diverse hardware platforms together. By leveraging this unified representation, TensorBind enables efficient tensor program optimization techniques across a wide range of hardware platforms. 
  We provide experimental results demonstrating the essentiality and adaptability of TensorBind in translating tensor program optimization records across multiple hardware architectures, 
  thus revolutionizing compilation optimization strategies and facilitating the development of high-performance compilation systems over heterogeneous devices.},
  year={2023}
}

@article{zhao2023miriam,
  abbr={SenSys'23},
  selected={true},
  title={Miriam: Exploiting Elastic Kernels for Real-time Multi-DNN Inference on Edge GPU},
  author={Zhao, Zhihe and Ling, Neiwen and Guan, Nan and Xing, Guoliang},
  journal = {Proceedings of the 21th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2023)},
  pdf={sensys23-miriam.pdf},
  html={https://arxiv.org/abs/2307.04339},
  abstract={Many applications such as autonomous driving and augmented reality, require the concurrent running of multiple deep neural networks (DNN) that poses different levels of real-time performance requirements. 
  However, coordinating multiple DNN tasks wth varying levels of criticality on edge GPUs remains an area of limited study. Unlike server-level GPUs, edge GPUs are resourcelimited and lack hardware-level resource management mechanisms for avoiding resource contention. 
  Therefore, we propose Miriam, a contention-aware task coordination framework for multi-DNN inference on edge GPU. Miriam consolidates two main components, an elastic-kernel generator, and a runtime dynamic kernel coordinator, to support mixed critical DNN inference. 
  To evaluate Miriam, we build a new DNN inference benchmark based on CUDA with diverse representative DNN workloads. Experiments on two edge GPU platforms show that Miriam can increase system throughput by 92% while only incurring less than 10% latency overhead for critical tasks, compared to state of art baselines.},
  year={2023},
  accept={(Acceptance ratio: 34/179=18.99%)}
}

@article{yang2023edgefm,
  abbr={SenSys'23},
  selected={true},
  title={EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge},
  author={Yang, Bufang and He, Lixing and Ling, Neiwen and Yan, Zhenyu and Xing, Guoliang and Shuai, Xian and Ren Xiaozhe and Xin Jiang},
  journal = {Proceedings of the 21th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2023)},
  pdf={sensys23-edgefm.pdf},
  abstract={Deep Learning (DL) models have been widely deployed on IoT devices with the help of advancements in DL algorithms and chips. 
  However, the limited resources of edge devices make these ondevice DL models hard to be generalizable to diverse environments and tasks. Although the recently emerged foundation models (FMs) show impressive generalization power, how to effectively leverage the rich knowledge of FMs on resource-limited edge devices is still not explored. 
  In this paper, we propose EdgeFM, a novel edge-cloud cooperative system with open-set recognition capability. EdgeFM selectively uploads unlabeled data to query the FM on the cloud and customizes the specific knowledge and architectures for edge models. Meanwhile, EdgeFM conducts dynamic model switching at run-time taking into account both data uncertainty and dynamic network variations, which ensures the accuracy always close to the original FM. 
  We implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on three public datasets and two self-collected datasets. Results show that EdgeFM can reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy increase compared with the baseline.},
  year={2023},
  accept={(Acceptance ratio: 34/179=18.99%)}
}

@article{ouyang2023Harmony,
  abbr={MobiSys'23},
  title={Harmony: Heterogeneous Multi-Modal Federated Learning through Disentangled Model Training},
  author={Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Pan, Li and Chen, Sitong and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei},
  journal = {The 21st ACM International Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2023)},
  year={2023},
  html={https://dl.acm.org/doi/abs/10.1145/3581791.3596844},
  pdf={mobisys23_harmony.pdf},
  abstract={Multi-modal sensing systems are increasingly prevalent in realworld applications such as health monitoring and autonomous driving. Most multi-modal learning approaches need to access users’ raw data, which poses significant concerns to users’ privacy. Federated learning (FL) provides a privacy-aware distributed learning framework. 
  However, current FL approaches have not addressed the unique challenges of heterogeneous multi-modal FL systems, such as modality heterogeneity and significantly longer training delay. 
  In this paper, we propose Harmony, a new system for heterogeneous multi-modal federated learning. Harmony disentangles the multimodal network training in a novel two-stage framework, namely modality-wise federated learning and federated fusion learning. 
  By integrating a novel balance-aware resource allocation mechanism in modality-wise FL and exploiting modality biases in federated fusion learning, Harmony improves the model accuracy under noni.i.d. data distributions and speeds up system convergence. 
  We implemented Harmony on a real-world multi-modal sensor testbed deployed in the homes of 16 elderly subjects for Alzheimer’s Disease monitoring. 
  Our evaluation on the testbed and three large-scale public datasets of different applications show that, Harmony outperforms by up to 46.35\% accuracy over state-of-the-art baselines and saves up to 30\% training delay.},
  accept={(Acceptance ratio: 41/198=20.7%)}
}


@article{xie2024timely,
  abbr={RTCSA'24},
  title={Timely Fusion of Surround Radar/Lidar for Object Detection in Autonomous Driving Systems},
  author={Xie, Wenjing and Hu, Tao and Ling, Neiwen and Xing, Guoliang and Xue, Chun Jason and Guan, Nan},
  journal = {he 30th IEEE International Conference on Embedded and Real-Time Computing Systems and Application,(IEEE RTCSA 2024)},
  year={2024},
  html={https://ieeexplore.ieee.org/abstract/document/10695646},
  pdf={timelyfusion.pdf},
  abstract={Fusion of multiple sensor modalities, such as camera, Lidar and Radar, are commonly used in autonomous driving systems to fully utilize the complementary advantages of different sensors. 
  Surround Radar/Lidar can provide 360-degree view sampling with the minimal cost, which are promising sensing hardware solutions for autonomous driving systems. However, due to the intrinsic physical constraints, the rotating speed (i.e., the frequency to generate data frames) of surround Radar is much lower than surround Lidar, and existing Radar/Lidar fusion methods have to work at the low frequency of surround Radar, which cannot meet the high responsiveness requirement of autonomous driving systems. 
  This paper develops techniques to fuse surround Radar/Lidar with working frequency only limited by the faster surround Lidar instead of the slower surround Radar, based on the state-of-the-art Radar/Lidar DNN model MVDNet. 
  The basic idea of our approach is simple: we let MVDNet work with temporally unaligned data from Radar/Lidar, so that fusion can take place at any time when a new Lidar data frame arrives, instead of waiting for the slow Radar data frame. 
  However, directly applying MVDNet to temporally unaligned Radar/Lidar data greatly degrades its object detection accuracy. 
  The key information revealed in this paper is that we can achieve high output frequency with little accuracy loss by enhancing the training procedure to explore the temporal redundancy in fusion procedure of MVDNet so that it can tolerate the temporal unalignment of the input data. 
  We explore several different ways of training enhancement and compare them quantitatively with experiments.}
}

@article{zhao2023moses,
  abbr={HotMobile'23},
  title={Moses: Exploiting Cross-device Transferable Features for On-device Tensor Program Optimization},
  author={Zhao, Zhihe and Shuai, Xian and Ling, Neiwen and Guan, Nan and Yan, Zhenyu and Xing, Guoliang},
  journal = {The 24th International Workshop on Mobile Computing Systems and Applications (ACM HotMobile 2023)},
  year={2023},
  abstract={Achieving efficient execution of machine learning models on mobile/edge devices has attracted significant attention recently. 
  A key challenge is to generate high-performance tensor programs for each operator inside a DNN model efficiently. To this end, deep learning compilers have adopted auto-tuning approaches such as Ansor. 
  However, it is challenging to optimize tensor codes for mobile/edge devices by auto-tuning due to limited time budgets and on-device resources. 
  A key component of DNN compilers is the cost model that can predict the performance of each configuration on specific devices. 
  However, current design of cost models cannot provide transferable features among different hardware accelerators efficiently and effectively. 
  In this paper, we propose Moses, a simple yet efficient design based on the lottery ticket hypothesis, which fully takes advantage of the hardware-agnostic features transferable to the target device via domain adaptation to optimize the time-consuming auto-tuning process of DNN compiling on a new hardware platform. 
  Compared with state-of-the-art approaches, Moses achieves up to 1.53X efficiency gain in the search stage and 1.41X inference speedup on challenging DNN benchmarks.},
  pdf={moses-hotmobile.pdf},
  html={https://dl.acm.org/doi/abs/10.1145/3572864.3580330}
}



@article{zhao2018ecrt,
  abbr={SenSys'18Demo},
  title={ECRT: An edge computing system for real-time image-based object tracking},
  author={Zhao, Zhihe and Jiang, Zhehao and Ling, Neiwen and Shuai, Xian and Xing, Guoliang},
  journal={Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems},
  pages={394--395},
  year={2018},
  abstract = {Real-time image-based object tracking from live video is of great importance for several smart city applications like surveillance, intelligent traffic management and autonomous driving. 
  Although recent deep learning systems can achieve satisfactory tracking performance, they incur significant compute overhead, which prevents them from wide adoption on resource-constrained IoT platforms. 
  In this demonstration, we present an Edge Computing system for Real-time object Tracking (ECRT) for resource-constrained devices. 
  The key feature of our system is that it intelligently partitions compute-intensive tasks such as inferencing a convolutional neural network(CNN) into two parts, which are executed locally on an IoT device and/or on the edge server. 
  Moreover, ECRT can minimize the power consumption of IoT devices while taking into consideration the dynamic network environment and user requirement on end to end delay.},
  doi={10.1145/3274783.3275199},
  url={https://dl.acm.org/doi/pdf/10.1145/3274783.3275199},
  html={https://dl.acm.org/doi/abs/10.1145/3274783.3275199},
  pdf={ECRT.pdf},
}

@article{zhao2021edgeml,
  abbr={IoTDI'21},
  title={EdgeML: An AutoML framework for real-time deep learning on the edge},
  author={Zhao, Zhihe and Wang, Kai and Ling, Neiwen and Xing, Guoliang},
  abstract = {In recent years, deep learning algorithms are increasingly adopted by a wide range of data-intensive and time-critical Internet of Things (IoT) applications. 
  As a result, several new approaches, including model partition/offloading and progressive neural architecture, have been proposed to address the challenge of deploying the computation-intensive deep neural network (DNN) models on resource-constrained edge devices. 
  However, the performance of existing approaches is highly affected by runtime dynamics. For example, offloading workload from edge to cloud suffers from communication delays and the efficiency of progressive neural architecture supporting early-exit DNN executions relies on input characteristics. 
  In this paper, we introduce EdgeML, an AutoML framework that provides flexible and fine-grained DNN model execution control by combining workload offloading mechanism and dynamic progressive neural architecture. 
  To achieve desirable latency-accuracy-energy system performance on edge platforms, EdgeML adopts reinforcement learning to automatically update model execution policy in response to runtime dynamics in real-time. We implement EdgeML for several widely used DNN models on the latest edge devices. 
  Comparing to existing approaches, our experiments show that EdgeML achieves up to 8x performance improvement under dynamic environments.},
  journal={Proceedings of the 6th International Conference on Internet-of-Things Design and Implementation (ACM/IEEE IoTDI 2021)},
  pages={133--144},
  year={2021},
  doi={10.1145/3450268.3453520},
  url={https://dl.acm.org/doi/pdf/10.1145/3450268.3453520},
  html={https://dl.acm.org/doi/abs/10.1145/3450268.3453520},
  pdf={EdgeML_IoTDI2021.pdf},
  accept={(Acceptance ratio: 19/74=25.7%)}
}

@article{ling2022dataset,
  abbr={SenSys'22Workshop},
  title={Dataset: An Indoor Smart Traffic Dataset and Data Collection System},
  author={Ling(co-primary), Neiwen and He(co-primary), Yuze and Guan, Nan and Fu, Heming and Xing, Guoliang},
  journal = {The 5th International SenSys/BuildSys Workshop on Data},
  year={2022},
  abstract={Smart traffic is an emerging research area gaining more attention due to a class of emerging applications such as autonomous driving. 
  Most smart traffic scenarios are outdoors, which are hard to collect traffic data and build demanding sensing systems. In this work, 
  an indoor smart traffic testbed with an F1TENTH autonomous driving vehicle is built, allowing the collection of traffic datasets 
  under different scenarios and performing various smart traffic tasks. This novel data collection system and collected dataset can help 
  research teams build various smart traffic systems and evaluate indoor smart traffic datasets. The collected traffic light dataset is 
  publicly available at the link1.},
  pdf={data22.pdf},
  html={https://dl.acm.org/doi/abs/10.1145/3560905.3567772},
  dataset={{https://zenodo.org/record/7181314#%23.Y0a0qXZBxD8}}
}

@article{zhao2022moses,
  abbr ={arXiv},
  title={Moses: Efficient Exploitation of Cross-device Transferable Features for Tensor Program Optimization},
  author={Zhao, Zhihe and Shuai, Xian and Bai, Yang and Ling, Neiwen and Guan, Nan and Yan, Zhenyu and Xing, Guoliang},
  abstract = {Achieving efficient execution of machine learning models has attracted significant attention recently. 
  To generate tensor programs efficiently, a key component of DNN compilers is the cost model that can predict the performance of each configuration on specific devices. 
  However, due to the rapid emergence of hardware platforms, it is increasingly labor-intensive to train domain-specific predictors for every new platform. 
  Besides, current design of cost models cannot provide transferable features between different hardware accelerators efficiently and effectively. 
  In this paper, we propose Moses, a simple and efficient design based on the lottery ticket hypothesis, which fully takes advantage of the features transferable to the target device via domain adaptation. 
  Compared with state-of-the-art approaches, Moses achieves up to 1.53X efficiency gain in the search stage and 1.41X inference speedup on challenging DNN benchmarks.},
  journal={arXiv preprint arXiv:2201.05752},
  year={2022},
  url={https://arxiv.org/pdf/2201.05752.pdf},
  html={https://arxiv.org/abs/2201.05752},
  pdf={moses.pdf},
}

