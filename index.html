<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Neiwen Ling</title> <meta name="author" content="Neiwen Ling"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="Internet of Things, Edge AI, Real-time Deep Learning, Real-time Scheduling"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/neiwen.github.io/assets/img/icon.png"/> <link rel="stylesheet" href="/neiwen.github.io/assets/css/main.css"> <link rel="canonical" href="https://neiwen.github.io/neiwen.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/neiwen.github.io/assets/js/theme.js"></script> <script src="/neiwen.github.io/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6E%65%69%77%65%6E.%6C%69%6E%67@%79%61%6C%65.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-2072-1502" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=ZtX9kXYAAAAJ&amp;hl=zh-CN" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Neiwen-Ling/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a> <a href="https://www.linkedin.com/in/neiwen-ling-1b115a170/?originalSubdomain=hk" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://dblp.org/pid/228/5904.html" title="DBLP" target="_blank" rel="noopener noreferrer"><i class="ai ai-dblp"></i></a> <a href="/neiwen.github.io/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/neiwen.github.io/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/neiwen.github.io/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/neiwen.github.io/awards/">Awards</a> </li> <li class="nav-item "> <a class="nav-link" href="/neiwen.github.io/services/">Services</a> </li> <li class="nav-item "> <a class="nav-link" href="/neiwen.github.io/projects/">Projects</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Neiwen Ling </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/neiwen.github.io/assets/img/neiwen25-4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/neiwen.github.io/assets/img/neiwen25-4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/neiwen.github.io/assets/img/neiwen25-4-1400.webp"></source> <img src="/neiwen.github.io/assets/img/neiwen25-4.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="neiwen25-4.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Neiwen Ling is currently a Postdoctoral Associate in the Efficient Computing Lab at Yale, working under the guidance of <a href="https://www.linzhong.org/" target="_blank" rel="noopener noreferrer noopener noreferrer">Prof. Lin Zhong</a>. She completed her Ph.D.(2022) at the Chinese University of Hong Kong, under the supervision of <a href="https://staff.ie.cuhk.edu.hk/~glxing/" target="_blank" rel="noopener noreferrer noopener noreferrer">Prof. Guoliang Xing</a>.</p> <p>Her research interests lie at the intersection of Edge Computing, Machine Learning, Cyber-Physical Systems(CPS)/Internet of Things(IoT), and Real-time Systems, with a focus on developing <strong>time-sensitive AI systems</strong> for <strong>physical agents</strong>. These systems have broad applications, including <strong>autonomous driving, robotics, and smart cities</strong>.</p> <ul> <li>Systems for LLM, Time-Sensitive LLM in CPS ( <a href="https://arxiv.org/pdf/2412.18695" target="_blank" rel="noopener noreferrer noopener noreferrer"> TimelyLLM </a>, <a href="https://arxiv.org/pdf/2312.14950" target="_blank" rel="noopener noreferrer noopener noreferrer"> TypeFly </a>)</li> <li>Concurrent DNN on Edge Platforms, Time-Sensitive DNN ( <a href="https://neawhen.github.io/neiwen.github.io/assets/pdf/blastnet_sensys2022.pdf" target="_blank" rel="noopener noreferrer noopener noreferrer"> BlastNet </a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3485730.3485938" target="_blank" rel="noopener noreferrer noopener noreferrer"> RT-mDL </a>)</li> <li>Distributed DNN, Cooperative Edge Computing (<a href="https://dl.acm.org/doi/pdf/10.1145/3636534.3649352" target="_blank" rel="noopener noreferrer noopener noreferrer"> Soar </a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3583120.3586955" target="_blank" rel="noopener noreferrer noopener noreferrer"> CoEdge </a>)</li> </ul> <p>She has published papers at several ACM/IEEE flagship conferences (e.g., SenSys, MobiCom, MobiSys, IPSN, and IoTDI), and received the ACM SenSys 2022 <strong>Best Paper Award Finalist</strong>, the ACM MobiCom 2024 <strong>Best Artifact Award Runner-Up</strong>, and the ACM SenSys 2022 <strong>Best Poster Award</strong>. She served as the program committee member for several ACM/IEEE flagship conferences, including SenSys25, ICPADS24 and CHASE23.</p> <p><a href="https://neawhen.github.io/neiwen.github.io/assets/pdf/CV_Neiwen.pdf" target="_blank" rel="noopener noreferrer noopener noreferrer"> CV </a> / <a href="https://neawhen.github.io/neiwen.github.io/projects/" target="_blank" rel="noopener noreferrer noopener noreferrer"> Projects </a> / <a href="https://scholar.google.com/citations?user=ZtX9kXYAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer noopener noreferrer"> Google Scholar </a></p> <p><a href="https://www.linkedin.com/in/neiwen-ling-1b115a170/?originalSubdomain=hk" target="_blank" rel="noopener noreferrer noopener noreferrer"> Linkedin </a> / Email: neiwen.ling@yale.edu</p> </div> <div class="news"> <h2>News</h2> <div class="table-responsive" style="max-height: 12vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">May 2025</th> <td> Honored to be selected as MobiSys’25 Rising Star </td> </tr> <tr> <th scope="row">Jan 2025</th> <td> Invited to deliver a talk at Athena Seminar Series </td> </tr> <tr> <th scope="row">Dec 2024</th> <td> Serve as the General Co-chair for <a href="https://fmsys-org.github.io/2025/index.html" target="_blank" rel="noopener noreferrer noopener noreferrer"> FMSys 2025 </a> at <a href="https://cps-iot-week2025.ics.uci.edu/" target="_blank" rel="noopener noreferrer noopener noreferrer"> CPS-IoT Week 2025 </a>. Welcome to submit! </td> </tr> <tr> <th scope="row">Nov 2024</th> <td> Our work Soar has won the Best Artifact Award Runner-Up at <a href="https://www.sigmobile.org/mobicom/2024/" target="_blank" rel="noopener noreferrer noopener noreferrer"> ACM MobiCom 2024 </a> </td> </tr> <tr> <th scope="row">Nov 2024</th> <td> Invited to serve on TPC for <a href="https://sensys.acm.org/2025/" target="_blank" rel="noopener noreferrer noopener noreferrer"> ACM SenSys 2025 </a> , welcome to submit! </td> </tr> </table> </div> </div> <div class="publications"> <h2>Selected Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SenSys’22</abbr></div> <div id="ling2022blastnet" class="col-sm-8"> <div class="title">BlastNet: Exploiting Duo-Blocks for Cross-Processor Real-Time DNN Inference</div> <div class="author"> <em>Neiwen Ling</em>, Xuan Huang, Zhihe Zhao, Nan Guan, Zhenyu Yan, and Guoliang Xing</div> <div class="periodical"> <em>The 20th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2022)</em><br><span style="color: #B71C1C"><b>Best Paper Finalist</b></span> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/abs/10.1145/3560905.3568520" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/neiwen.github.io/assets/pdf/blastnet_sensys2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/neiwen.github.io/assets/pdf/Blastnet-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>In recent years, Deep Neural Network (DNN) has been increasingly adopted by a wide range of time-critical applications running on edge platforms with heterogeneous multiprocessors. To meet the stringent timing requirements of these applications, heterogeneous CPU and GPU resources must be efficiently utilized for the inference of multiple DNN models. Such a cross-processor real-time DNN inference paradigm poses major challenges due to the inherent performance imbalance among different processors and the lack of real-time support for cross-processor inference from existing deep learning frameworks. In this work, we propose a new system named BlastNet that exploits duo-block - a new model inference abstraction to support highly efficient cross-processor real-time DNN inference. Each duo-block has a dual model structure, enabling efficient fine-grained inference alternatively across different processors. BlastNet employs a novel block-level Neural Architecture Search (NAS) technique to generate duo-blocks, which accounts for computing characteristics and communication overhead. The duoblocks are optimized at design time and then dynamically scheduled to achieve high resource utilization of heterogeneous CPU and GPU at runtime. BlastNet is implemented on an indoor autonomous driving platform and three popular edge platforms. Extensive results show that BlastNet achieves 35.07 % less deadline missing rate with a mere 1.63% of model accuracy loss.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arxiv</abbr></div> <div id="2024timelyllm" class="col-sm-8"> <div class="title">TimelyLLM: Segmented LLM Serving System for Time-sensitive Robotic Applications</div> <div class="author"> <em>Neiwen Ling</em>, Guojun Chen, and Lin Zhong</div> <div class="periodical"> <em>arXiv preprint arXiv:2412.18695</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2412.18695" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/neiwen.github.io/assets/pdf/timelyllm.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) such as GPT-4 and Llama3 can already comprehend complex commands and process diverse tasks. This advancement facilitates their application in controlling drones and robots for various tasks. However, existing LLM serving systems typically employ a first-come, first-served (FCFS) batching mechanism, which fails to address the time-sensitive requirements of robotic applications. To address it, this paper proposes a new system named TimelyLLM serving multiple robotic agents with time-sensitive requests. TimelyLLM introduces novel mechanisms of segmented generation and scheduling that optimally leverage redundancy between robot plan generation and execution phases. We report an implementation of TimelyLLM on a widely-used LLM serving framework and evaluate it on a range of robotic applications. Our evaluation shows that TimelyLLM improves the time utility up to 1.97x, and reduces the overall waiting time by 84%.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SenSys’21</abbr></div> <div id="ling2021rt" class="col-sm-8"> <div class="title">RT-mDL: Supporting Real-Time Mixed Deep Learning Tasks on Edge Platforms</div> <div class="author"> <em>Neiwen Ling</em>, Kai Wang, Yuze He, Guoliang Xing, and Daqi Xie</div> <div class="periodical"> <em>The 19th ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2021)</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3485730.3485938" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.youtube.com/watch?v=9Hh1NOyXqPU&amp;t=8s" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> <a href="https://www.youtube.com/watch?v=7-_t1MrIo04" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Demo</a> <a href="/neiwen.github.io/assets/pdf/RT-mDL_SenSys2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/neiwen.github.io/assets/pdf/RT-mDL-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Recent years have witnessed an emerging class of real-time applications, e.g., autonomous driving, in which resource-constrained edge platforms need to execute a set of real-time mixed Deep Learning (DL) tasks concurrently. Such an application paradigm poses major challenges due to the huge compute workload of deep neural network models, diverse performance requirements of different tasks, and the lack of real-time support from existing DL frameworks. In this paper, we present RT-mDL, a novel framework to support mixed real-time DL tasks on edge platform with heterogeneous CPU and GPU resource. RT-mDL aims to optimize the mixed DL task execution to meet their diverse real-time/accuracy requirements by exploiting unique compute characteristics of DL tasks. RT-mDL employs a novel storage-bounded model scaling method to generate a series of model variants, and systematically optimizes the DL task execution by joint model variants selection and task priority assignment. To improve the CPU/GPU utilization of mixed DL tasks, RT-mDL also includes a new priority-based scheduler which employs a GPU packing mechanism and executes the CPU/GPU tasks independently. Our implementation on an F1/10 autonomous driving testbed shows that, RT-mDL can enable multiple concurrent DL tasks to achieve satisfactory real-time performance in traffic light detection and sign recognition. Moreover, compared to state-of-the-art baselines, RT-mDL can reduce deadline missing rate by 40.12% while only sacrificing 1.7% model accuracy. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MobiCom’24</abbr></div> <div id="2024soar" class="col-sm-8"> <div class="title">Soar: Design and Deployment of A Smart Roadside Infrastructure System for Autonomous Driving</div> <div class="author"> Shuyao Shi(co-primary), <em>Neiwen Ling(co-primary)</em>, Zhehao Jiang(co-primary), Xuan Huang(co-primary), Yuze He, Xiaoguang Zhao, Bufang Yang, Chen Bian, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Jingfei Xia, Zhenyu Yan, Raymond Yeung, Guoliang Xing' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>The 30th Annual International Conference on Mobile Computing And Networking (ACM MobiCom 2024)</em><br><span style="color: #B71C1C"><b>Best Artifact Award Runner-Up</b></span> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3636534.3649352" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/neiwen.github.io/assets/pdf/soar_mobicom24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Recently, smart roadside infrastructure (SRI) has demonstrated the potential of achieving fully autonomous driving systems. To explore the potential of infrastructure-assisted autonomous driving, this paper presents the design and deployment of Soar, the first end-to-end SRI system specifically designed to support autonomous driving systems. Soar consists of both software and hardware components carefully designed to overcome various system and physical challenges. Soar can leverage the existing operational infrastructure like street lampposts for a lower barrier of adoption. Soar adopts a new communication architecture that comprises a bi-directional multi-hop I2I network and a downlink I2V broadcast service, which are designed based on off-the-shelf 802.11ac interfaces in an integrated manner. Soar also features a hierarchical DL task management framework to achieve desirable load balancing among nodes and enable them to collaborate efficiently to run multiple data-intensive autonomous driving applications. We deployed a total of 18 Soar nodes on existing lampposts on campus, which have been operational for over two years. Our real-world evaluation shows that Soar can support a diverse set of autonomous driving applications and achieve desirable real-time performance and high communication reliability. Our findings and experiences in this work offer key insights into the development and deployment of next-generation smart roadside infrastructure and autonomous driving systems.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IPSN’23</abbr></div> <div id="jiang2023coedge" class="col-sm-8"> <div class="title">CoEdge: A Cooperative Edge System for Distributed Real-Time Deep Learning Tasks</div> <div class="author"> Zhehao Jiang(co-primary), <em>Neiwen Ling(co-primary)</em>, Xuan Huang, Shuyao Shi, Chenhao Wu, Xiaoguang Zhao, Zhenyu Yan, and Guoliang Xing</div> <div class="periodical"> <em>The 22nd ACM/IEEE Conference on Information Processing in Sensor Networks (ACM/IEEE IPSN 2023)</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3583120.3586955" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/neiwen.github.io/assets/pdf/coedge_ipsn23.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/neiwen.github.io/assets/pdf/CoEdge_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Recent years have witnessed the emergence of a new class of cooperative edge systems in which a large number of edge nodes can collaborate through local peer-to-peer connectivity. In this paper, we propose CoEdge, a novel cooperative edge system that can support concurrent data/compute-intensive deep learning (DL) models for distributed real-time applications such as city-scale traffic monitoring and autonomous driving. First, CoEdge includes a hierarchical DL task scheduling framework that dispatches DL tasks to edge nodes based on their computational profiles, communication overhead, and real-time requirements. Second, CoEdge can dramatically increase the execution efficiency of DL models by batching sensor data and aggregating the inferences of the same model. Finally, we propose a new edge containerization approach that enables an edge node to execute concurrent DL tasks by partitioning the CPU and GPU workloads into different containers. We extensively evaluate CoEdge on a self-deployed smart lamppost testbed on a university campus. Our results show that CoEdge can achieve up to 82.32% reduction on deadline missing rate compared to baselines.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TMC’25</abbr></div> <div id="2025chatfly" class="col-sm-8"> <div class="title">TypeFly: Low-Latency Drone Planning with Large Language Models</div> <div class="author"> Guojun Chen, Xiaojing Yu, <em>Neiwen Ling</em>, and Lin Zhong</div> <div class="periodical"> <em>to apper in IEEE Trans. Mobile Computing,</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p> </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SenSys’22Poster</abbr></div> <div id="zhao2022iot" class="col-sm-8"> <div class="title">Aaron: Compile-time Kernel Adaptation for Multi-DNN Inference Acceleration on Edge GPU</div> <div class="author"> Zhihe Zhao, <em>Neiwen Ling</em>, Nan Guan, and Guoliang Xing</div> <div class="periodical"> <em>The 20th ACM Conference on Embedded Networked Sensor Systems</em><br><span style="color: #B71C1C"><b>Best Poster Award</b></span> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/10.1145/3560905.3568050" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/neiwen.github.io/assets/pdf/aaron_sensys2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>AI applications powered by deep learning are increasingly running on edge devices. Meanwhile, many real-world IoT applications demand multiple real-time tasks to run on the same device, for example, to achieve both object tracking and image segmentation simultaneously on an augmented reality glass. However, the current solutions can not yet support such multi-tenant real-time DNN inference on edge devices. Techniques such as on-device model compression trade inference accuracy for speed, while traditional DNN compilers mainly focus on single-tenant DNN model optimization. To fill this gap, we propose Aaron, which leverages DNN compiling techniques to accelerate multi-DNN inference on edge GPU based on compile-time kernel adaptation with no accuracy loss. Aaron integrates both DNN graph and kernel optimization to maximize on-device parallelism and minimize contention brought by concurrent inference.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SenSys’23</abbr></div> <div id="zhao2023miriam" class="col-sm-8"> <div class="title">Miriam: Exploiting Elastic Kernels for Real-time Multi-DNN Inference on Edge GPU</div> <div class="author"> Zhihe Zhao, <em>Neiwen Ling</em>, Nan Guan, and Guoliang Xing</div> <div class="periodical"> <em>The 21st ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2023)</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2307.04339" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/neiwen.github.io/assets/pdf/sensys23-miriam.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Many applications such as autonomous driving and augmented reality, require the concurrent running of multiple deep neural networks (DNN) that poses different levels of real-time performance requirements. However, coordinating multiple DNN tasks wth varying levels of criticality on edge GPUs remains an area of limited study. Unlike server-level GPUs, edge GPUs are resourcelimited and lack hardware-level resource management mechanisms for avoiding resource contention. Therefore, we propose Miriam, a contention-aware task coordination framework for multi-DNN inference on edge GPU. Miriam consolidates two main components, an elastic-kernel generator, and a runtime dynamic kernel coordinator, to support mixed critical DNN inference. To evaluate Miriam, we build a new DNN inference benchmark based on CUDA with diverse representative DNN workloads. Experiments on two edge GPU platforms show that Miriam can increase system throughput by 92% while only incurring less than 10% latency overhead for critical tasks, compared to state of art baselines.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SenSys’23</abbr></div> <div id="yang2023edgefm" class="col-sm-8"> <div class="title">EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge</div> <div class="author"> Bufang Yang, Lixing He, <em>Neiwen Ling</em>, Zhenyu Yan, Guoliang Xing, Xian Shuai, Ren Xiaozhe, and Xin Jiang</div> <div class="periodical"> <em>The 21st ACM Conference on Embedded Networked Sensor Systems (ACM SenSys 2023)</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/neiwen.github.io/assets/pdf/sensys23-edgefm.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Deep Learning (DL) models have been widely deployed on IoT devices with the help of advancements in DL algorithms and chips. However, the limited resources of edge devices make these ondevice DL models hard to be generalizable to diverse environments and tasks. Although the recently emerged foundation models (FMs) show impressive generalization power, how to effectively leverage the rich knowledge of FMs on resource-limited edge devices is still not explored. In this paper, we propose EdgeFM, a novel edge-cloud cooperative system with open-set recognition capability. EdgeFM selectively uploads unlabeled data to query the FM on the cloud and customizes the specific knowledge and architectures for edge models. Meanwhile, EdgeFM conducts dynamic model switching at run-time taking into account both data uncertainty and dynamic network variations, which ensures the accuracy always close to the original FM. We implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on three public datasets and two self-collected datasets. Results show that EdgeFM can reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy increase compared with the baseline.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%65%69%77%65%6E.%6C%69%6E%67@%79%61%6C%65.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-2072-1502" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=ZtX9kXYAAAAJ&amp;hl=zh-CN" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Neiwen-Ling/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a> <a href="https://www.linkedin.com/in/neiwen-ling-1b115a170/?originalSubdomain=hk" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://dblp.org/pid/228/5904.html" title="DBLP" target="_blank" rel="noopener noreferrer"><i class="ai ai-dblp"></i></a> <a href="/neiwen.github.io/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> Feel free to reach out to me via email neiwen.ling@yale.edu </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Neiwen Ling. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: August 16, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/neiwen.github.io/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/neiwen.github.io/assets/js/zoom.js"></script> <script defer src="/neiwen.github.io/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>